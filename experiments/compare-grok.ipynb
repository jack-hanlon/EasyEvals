{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_eval_path = \"logs-json/2024-11-23T00-27-58-08-00_theory-of-mind_fZviDx4z7a8UaPgMmCNmpD.json\"\n",
    "claude_3_sonnet_eval_path = \"logs-json/2024-11-23T10-44-13-08-00_theory-of-mind_Ehd35cmCvqzUJmLrKpJTXi.json\"\n",
    "gemini_1_5_flash_eval_path = \"logs-json/2024-11-23T10-58-18-08-00_theory-of-mind_3xrMbdT8mbuDe78pZj6n4h.json\"\n",
    "grok_beta_eval_path = \"logs-json/2024-11-23T11-01-41-08-00_theory-of-mind_GCZsTqfGL8YygNvSP9vZSD.json\"\n",
    "grok_vision_beta_eval_path = \"logs-json/2024-11-23T11-12-29-08-00_theory-of-mind_fBnWBgug2x4YvmxSWWep5r.json\"\n",
    "\n",
    "with open(gpt_4_eval_path, \"r\") as f:\n",
    "    gpt_4_eval_data = dict(json.load(f))\n",
    "\n",
    "with open(claude_3_sonnet_eval_path, \"r\") as f:\n",
    "    claude_3_sonnet_eval_data = dict(json.load(f))\n",
    "\n",
    "with open(gemini_1_5_flash_eval_path, \"r\") as f:\n",
    "    gemini_1_5_flash_eval_data = dict(json.load(f))\n",
    "\n",
    "\n",
    "with open(grok_beta_eval_path, \"r\") as f:\n",
    "    grok_beta_eval_data = dict(json.load(f))\n",
    "\n",
    "\n",
    "with open(grok_vision_beta_eval_path, \"r\") as f:\n",
    "    grok_vision_beta_eval_data = dict(json.load(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>stderr</th>\n",
       "      <th>run_start</th>\n",
       "      <th>run_end</th>\n",
       "      <th>run_input_tokens</th>\n",
       "      <th>run_output_tokens</th>\n",
       "      <th>run_total_tokens</th>\n",
       "      <th>upper_bound</th>\n",
       "      <th>lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GFJUCeSDrcsJMzch5HZ5an</td>\n",
       "      <td>theory_of_mind</td>\n",
       "      <td>openai/gpt-4</td>\n",
       "      <td>{prompt}</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>2024-11-23T00:27:58-08:00</td>\n",
       "      <td>2024-11-23T00:40:23-08:00</td>\n",
       "      <td>75395</td>\n",
       "      <td>19493</td>\n",
       "      <td>94888</td>\n",
       "      <td>0.870235</td>\n",
       "      <td>0.709765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7sTJLizK2fWUmunLGZ45Bo</td>\n",
       "      <td>theory_of_mind</td>\n",
       "      <td>anthropic/claude-3-5-sonnet-latest</td>\n",
       "      <td>{prompt}</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.039428</td>\n",
       "      <td>2024-11-23T10:44:13-08:00</td>\n",
       "      <td>2024-11-23T12:07:27-08:00</td>\n",
       "      <td>113609</td>\n",
       "      <td>40982</td>\n",
       "      <td>154591</td>\n",
       "      <td>0.887278</td>\n",
       "      <td>0.732722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XYMM64LW4txoCvQgJBoAEt</td>\n",
       "      <td>theory_of_mind</td>\n",
       "      <td>google/gemini-1.5-flash-001</td>\n",
       "      <td>{prompt}</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.047258</td>\n",
       "      <td>2024-11-23T10:58:18-08:00</td>\n",
       "      <td>2024-11-23T11:36:30-08:00</td>\n",
       "      <td>116382</td>\n",
       "      <td>39693</td>\n",
       "      <td>156075</td>\n",
       "      <td>0.762626</td>\n",
       "      <td>0.577374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9CZwNdPp8pMQdy5cWZeLiP</td>\n",
       "      <td>theory_of_mind</td>\n",
       "      <td>grok/grok-beta</td>\n",
       "      <td>{prompt}</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.038612</td>\n",
       "      <td>2024-11-23T11:01:41-08:00</td>\n",
       "      <td>2024-11-23T11:03:15-08:00</td>\n",
       "      <td>91260</td>\n",
       "      <td>33541</td>\n",
       "      <td>124801</td>\n",
       "      <td>0.895680</td>\n",
       "      <td>0.744320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bzJFKKPmkGZXmbDQroL6LQ</td>\n",
       "      <td>theory_of_mind</td>\n",
       "      <td>grok/grok-vision-beta</td>\n",
       "      <td>{prompt}</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.040202</td>\n",
       "      <td>2024-11-23T11:12:29-08:00</td>\n",
       "      <td>2024-11-23T11:13:45-08:00</td>\n",
       "      <td>87505</td>\n",
       "      <td>30140</td>\n",
       "      <td>117645</td>\n",
       "      <td>0.878795</td>\n",
       "      <td>0.721205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   run_id         dataset                               model  \\\n",
       "0  GFJUCeSDrcsJMzch5HZ5an  theory_of_mind                        openai/gpt-4   \n",
       "1  7sTJLizK2fWUmunLGZ45Bo  theory_of_mind  anthropic/claude-3-5-sonnet-latest   \n",
       "2  XYMM64LW4txoCvQgJBoAEt  theory_of_mind         google/gemini-1.5-flash-001   \n",
       "3  9CZwNdPp8pMQdy5cWZeLiP  theory_of_mind                      grok/grok-beta   \n",
       "4  bzJFKKPmkGZXmbDQroL6LQ  theory_of_mind               grok/grok-vision-beta   \n",
       "\n",
       "     prompt  accuracy    stderr                  run_start  \\\n",
       "0  {prompt}      0.79  0.040936  2024-11-23T00:27:58-08:00   \n",
       "1  {prompt}      0.81  0.039428  2024-11-23T10:44:13-08:00   \n",
       "2  {prompt}      0.67  0.047258  2024-11-23T10:58:18-08:00   \n",
       "3  {prompt}      0.82  0.038612  2024-11-23T11:01:41-08:00   \n",
       "4  {prompt}      0.80  0.040202  2024-11-23T11:12:29-08:00   \n",
       "\n",
       "                     run_end  run_input_tokens  run_output_tokens  \\\n",
       "0  2024-11-23T00:40:23-08:00             75395              19493   \n",
       "1  2024-11-23T12:07:27-08:00            113609              40982   \n",
       "2  2024-11-23T11:36:30-08:00            116382              39693   \n",
       "3  2024-11-23T11:03:15-08:00             91260              33541   \n",
       "4  2024-11-23T11:13:45-08:00             87505              30140   \n",
       "\n",
       "   run_total_tokens  upper_bound  lower_bound  \n",
       "0             94888     0.870235     0.709765  \n",
       "1            154591     0.887278     0.732722  \n",
       "2            156075     0.762626     0.577374  \n",
       "3            124801     0.895680     0.744320  \n",
       "4            117645     0.878795     0.721205  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_data(eval_data):\n",
    "    dataset = eval_data['eval']['dataset']['name']\n",
    "    model = eval_data['eval']['model']\n",
    "    prompt = eval_data['plan']['steps'][0]['params']['template']\n",
    "    accuracy = eval_data['results']['scores'][0]['metrics']['accuracy']['value']\n",
    "    stderr = eval_data['results']['scores'][0]['metrics']['stderr']['value']\n",
    "    run_start = eval_data['stats']['started_at']\n",
    "    run_end = eval_data['stats']['completed_at']\n",
    "    run_input_tokens = eval_data['stats']['model_usage'][model]['input_tokens']\n",
    "    run_output_tokens = eval_data['stats']['model_usage'][model]['output_tokens']\n",
    "    run_total_tokens = eval_data['stats']['model_usage'][model]['total_tokens']\n",
    "    run_id = eval_data['eval']['run_id']\n",
    "    run_data = {\n",
    "        'run_id': run_id,\n",
    "        'dataset': dataset,\n",
    "        'model': model,\n",
    "    'prompt': prompt,\n",
    "    'accuracy': accuracy,\n",
    "    'stderr': stderr,\n",
    "    'run_start': run_start,\n",
    "    'run_end': run_end,\n",
    "    'run_input_tokens': run_input_tokens,\n",
    "    'run_output_tokens': run_output_tokens,\n",
    "    'run_total_tokens': run_total_tokens\n",
    "}\n",
    "\n",
    "    run_data_df = pd.DataFrame([run_data])\n",
    "    run_data_df['upper_bound'] = run_data_df['accuracy'] + 1.96 * run_data_df['stderr']\n",
    "    run_data_df['lower_bound'] = run_data_df['accuracy'] - 1.96 * run_data_df['stderr']\n",
    "\n",
    "    return run_data_df\n",
    "\n",
    "# Get eval data for every file and concatenate to one DataFrame\n",
    "eval_files = [\n",
    "    gpt_4_eval_data,\n",
    "    claude_3_sonnet_eval_data,\n",
    "    gemini_1_5_flash_eval_data,\n",
    "    grok_beta_eval_data,\n",
    "    grok_vision_beta_eval_data\n",
    "]\n",
    "\n",
    "gpt_4_run_data_df = get_run_data(gpt_4_eval_data)\n",
    "claude_3_sonnet_run_data_df = get_run_data(claude_3_sonnet_eval_data)\n",
    "gemini_1_5_flash_run_data_df = get_run_data(gemini_1_5_flash_eval_data)\n",
    "grok_beta_run_data_df = get_run_data(grok_beta_eval_data)\n",
    "grok_vision_beta_run_data_df = get_run_data(grok_vision_beta_eval_data)\n",
    "\n",
    "all_run_data_df = pd.concat([gpt_4_run_data_df, claude_3_sonnet_run_data_df, gemini_1_5_flash_run_data_df, grok_beta_run_data_df, grok_vision_beta_run_data_df], ignore_index=True)\n",
    "\n",
    "all_run_data_df.to_json('all_run_data.json', orient='records')\n",
    "\n",
    "all_run_data_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>epoch</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>output</th>\n",
       "      <th>score</th>\n",
       "      <th>score_binary</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>cumulative_score_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GFJUCeSDrcsJMzch5HZ5an</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jackson entered the hall. Chloe entered the ha...</td>\n",
       "      <td>bathtub</td>\n",
       "      <td>ANSWER: The boots were in the bathtub at the b...</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GFJUCeSDrcsJMzch5HZ5an</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Jackson entered the hall. Chloe entered the ha...</td>\n",
       "      <td>pantry</td>\n",
       "      <td>ANSWER: Chloe will look for the boots in the p...</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GFJUCeSDrcsJMzch5HZ5an</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Jackson entered the hall. Chloe entered the ha...</td>\n",
       "      <td>bathtub</td>\n",
       "      <td>ANSWER: Chloe would think that Jackson is sear...</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GFJUCeSDrcsJMzch5HZ5an</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Jackson entered the hall. Chloe entered the ha...</td>\n",
       "      <td>pantry</td>\n",
       "      <td>ANSWER: The boots are really in the pantry.</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GFJUCeSDrcsJMzch5HZ5an</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Jackson entered the hall. Chloe entered the ha...</td>\n",
       "      <td>bathtub</td>\n",
       "      <td>ANSWER: Jackson will look for the boots in the...</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>bzJFKKPmkGZXmbDQroL6LQ</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>Ethan entered the sunroom. Mia entered the sun...</td>\n",
       "      <td>box</td>\n",
       "      <td>ANSWER: Ethan would think that Mia searches fo...</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.802083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>bzJFKKPmkGZXmbDQroL6LQ</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>Lily entered the patio. Logan entered the pati...</td>\n",
       "      <td>crate</td>\n",
       "      <td>ANSWER: At the beginning, the tie was in the c...</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0.804124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>bzJFKKPmkGZXmbDQroL6LQ</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>Lily entered the patio. Logan entered the pati...</td>\n",
       "      <td>bucket</td>\n",
       "      <td>ANSWER: Lily will look for the tie in the buck...</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>0.806122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>bzJFKKPmkGZXmbDQroL6LQ</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>Lily entered the patio. Logan entered the pati...</td>\n",
       "      <td>bucket</td>\n",
       "      <td>ANSWER: Lily would likely think that Abigail w...</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0.797980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>bzJFKKPmkGZXmbDQroL6LQ</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>Lily entered the patio. Logan entered the pati...</td>\n",
       "      <td>bucket</td>\n",
       "      <td>ANSWER: The tie is really in the bucket. Lily ...</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     run_id  sample_id  epoch  \\\n",
       "0    GFJUCeSDrcsJMzch5HZ5an          1      1   \n",
       "1    GFJUCeSDrcsJMzch5HZ5an          2      1   \n",
       "2    GFJUCeSDrcsJMzch5HZ5an          3      1   \n",
       "3    GFJUCeSDrcsJMzch5HZ5an          4      1   \n",
       "4    GFJUCeSDrcsJMzch5HZ5an          5      1   \n",
       "..                      ...        ...    ...   \n",
       "495  bzJFKKPmkGZXmbDQroL6LQ         96      1   \n",
       "496  bzJFKKPmkGZXmbDQroL6LQ         97      1   \n",
       "497  bzJFKKPmkGZXmbDQroL6LQ         98      1   \n",
       "498  bzJFKKPmkGZXmbDQroL6LQ         99      1   \n",
       "499  bzJFKKPmkGZXmbDQroL6LQ        100      1   \n",
       "\n",
       "                                                 input   target  \\\n",
       "0    Jackson entered the hall. Chloe entered the ha...  bathtub   \n",
       "1    Jackson entered the hall. Chloe entered the ha...   pantry   \n",
       "2    Jackson entered the hall. Chloe entered the ha...  bathtub   \n",
       "3    Jackson entered the hall. Chloe entered the ha...   pantry   \n",
       "4    Jackson entered the hall. Chloe entered the ha...  bathtub   \n",
       "..                                                 ...      ...   \n",
       "495  Ethan entered the sunroom. Mia entered the sun...      box   \n",
       "496  Lily entered the patio. Logan entered the pati...    crate   \n",
       "497  Lily entered the patio. Logan entered the pati...   bucket   \n",
       "498  Lily entered the patio. Logan entered the pati...   bucket   \n",
       "499  Lily entered the patio. Logan entered the pati...   bucket   \n",
       "\n",
       "                                                output score  score_binary  \\\n",
       "0    ANSWER: The boots were in the bathtub at the b...     C             1   \n",
       "1    ANSWER: Chloe will look for the boots in the p...     C             1   \n",
       "2    ANSWER: Chloe would think that Jackson is sear...     I             0   \n",
       "3          ANSWER: The boots are really in the pantry.     C             1   \n",
       "4    ANSWER: Jackson will look for the boots in the...     I             0   \n",
       "..                                                 ...   ...           ...   \n",
       "495  ANSWER: Ethan would think that Mia searches fo...     C             1   \n",
       "496  ANSWER: At the beginning, the tie was in the c...     C             1   \n",
       "497  ANSWER: Lily will look for the tie in the buck...     C             1   \n",
       "498  ANSWER: Lily would likely think that Abigail w...     I             0   \n",
       "499  ANSWER: The tie is really in the bucket. Lily ...     C             1   \n",
       "\n",
       "     cumulative_score  cumulative_score_percentage  \n",
       "0                   1                     1.000000  \n",
       "1                   2                     1.000000  \n",
       "2                   2                     0.666667  \n",
       "3                   3                     0.750000  \n",
       "4                   3                     0.600000  \n",
       "..                ...                          ...  \n",
       "495                77                     0.802083  \n",
       "496                78                     0.804124  \n",
       "497                79                     0.806122  \n",
       "498                79                     0.797980  \n",
       "499                80                     0.800000  \n",
       "\n",
       "[500 rows x 10 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_samples_data(samples, run_id):\n",
    "    final_samples = []\n",
    "\n",
    "    for sample in samples:   \n",
    "        \n",
    "        sample_id = sample['id']\n",
    "        epoch = sample['epoch']\n",
    "        input = sample['input'][0]['content']\n",
    "        target = sample['target']\n",
    "        messages = sample['messages']\n",
    "        output = sample['output']['choices'][0]['message']['content']\n",
    "        score = sample['scores']['model_graded_fact']['value']\n",
    "\n",
    "        final_samples.append({\n",
    "            'run_id': run_id,\n",
    "            'sample_id': sample_id,\n",
    "            'epoch': epoch,\n",
    "            'input': input,\n",
    "            'target': target,\n",
    "            'output': output,\n",
    "            'score': score,\n",
    "        })\n",
    "        \n",
    "    df = pd.DataFrame(final_samples)\n",
    "    df['score_binary'] = df['score'].apply(lambda x: 1 if x == 'C' else 0)\n",
    "    df['cumulative_score'] = df['score_binary'].cumsum()\n",
    "    df['cumulative_score_percentage'] = df['cumulative_score'] / df['sample_id']\n",
    "\n",
    "    return df\n",
    "\n",
    "gpt_4_samples_data_df = get_samples_data(gpt_4_eval_data['samples'], gpt_4_eval_data['eval']['run_id'])\n",
    "claude_3_sonnet_samples_data_df = get_samples_data(claude_3_sonnet_eval_data['samples'], claude_3_sonnet_eval_data['eval']['run_id'])\n",
    "gemini_1_5_flash_samples_data_df = get_samples_data(gemini_1_5_flash_eval_data['samples'], gemini_1_5_flash_eval_data['eval']['run_id'])\n",
    "grok_beta_samples_data_df = get_samples_data(grok_beta_eval_data['samples'], grok_beta_eval_data['eval']['run_id'])\n",
    "grok_vision_beta_samples_data_df = get_samples_data(grok_vision_beta_eval_data['samples'], grok_vision_beta_eval_data['eval']['run_id'])\n",
    "\n",
    "\n",
    "all_samples_data_df = pd.concat([gpt_4_samples_data_df, claude_3_sonnet_samples_data_df, gemini_1_5_flash_samples_data_df, grok_beta_samples_data_df, grok_vision_beta_samples_data_df], ignore_index=True)\n",
    "\n",
    "all_samples_data_df.to_json('all_samples_data.json', orient='records')\n",
    "\n",
    "all_samples_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>stderr</th>\n",
       "      <th>run_start</th>\n",
       "      <th>run_end</th>\n",
       "      <th>run_input_tokens</th>\n",
       "      <th>run_output_tokens</th>\n",
       "      <th>run_total_tokens</th>\n",
       "      <th>upper_bound</th>\n",
       "      <th>lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GFJUCeSDrcsJMzch5HZ5an</td>\n",
       "      <td>openai/gpt-4</td>\n",
       "      <td>{prompt}</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>2024-11-23T00:27:58-08:00</td>\n",
       "      <td>2024-11-23T00:40:23-08:00</td>\n",
       "      <td>75395</td>\n",
       "      <td>19493</td>\n",
       "      <td>94888</td>\n",
       "      <td>0.870235</td>\n",
       "      <td>0.709765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7sTJLizK2fWUmunLGZ45Bo</td>\n",
       "      <td>anthropic/claude-3-5-sonnet-latest</td>\n",
       "      <td>{prompt}</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.039428</td>\n",
       "      <td>2024-11-23T10:44:13-08:00</td>\n",
       "      <td>2024-11-23T12:07:27-08:00</td>\n",
       "      <td>113609</td>\n",
       "      <td>40982</td>\n",
       "      <td>154591</td>\n",
       "      <td>0.887278</td>\n",
       "      <td>0.732722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XYMM64LW4txoCvQgJBoAEt</td>\n",
       "      <td>google/gemini-1.5-flash-001</td>\n",
       "      <td>{prompt}</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.047258</td>\n",
       "      <td>2024-11-23T10:58:18-08:00</td>\n",
       "      <td>2024-11-23T11:36:30-08:00</td>\n",
       "      <td>116382</td>\n",
       "      <td>39693</td>\n",
       "      <td>156075</td>\n",
       "      <td>0.762626</td>\n",
       "      <td>0.577374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9CZwNdPp8pMQdy5cWZeLiP</td>\n",
       "      <td>grok/grok-beta</td>\n",
       "      <td>{prompt}</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.038612</td>\n",
       "      <td>2024-11-23T11:01:41-08:00</td>\n",
       "      <td>2024-11-23T11:03:15-08:00</td>\n",
       "      <td>91260</td>\n",
       "      <td>33541</td>\n",
       "      <td>124801</td>\n",
       "      <td>0.895680</td>\n",
       "      <td>0.744320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bzJFKKPmkGZXmbDQroL6LQ</td>\n",
       "      <td>grok/grok-vision-beta</td>\n",
       "      <td>{prompt}</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.040202</td>\n",
       "      <td>2024-11-23T11:12:29-08:00</td>\n",
       "      <td>2024-11-23T11:13:45-08:00</td>\n",
       "      <td>87505</td>\n",
       "      <td>30140</td>\n",
       "      <td>117645</td>\n",
       "      <td>0.878795</td>\n",
       "      <td>0.721205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   run_id                               model    prompt  \\\n",
       "0  GFJUCeSDrcsJMzch5HZ5an                        openai/gpt-4  {prompt}   \n",
       "1  7sTJLizK2fWUmunLGZ45Bo  anthropic/claude-3-5-sonnet-latest  {prompt}   \n",
       "2  XYMM64LW4txoCvQgJBoAEt         google/gemini-1.5-flash-001  {prompt}   \n",
       "3  9CZwNdPp8pMQdy5cWZeLiP                      grok/grok-beta  {prompt}   \n",
       "4  bzJFKKPmkGZXmbDQroL6LQ               grok/grok-vision-beta  {prompt}   \n",
       "\n",
       "   accuracy    stderr                  run_start                    run_end  \\\n",
       "0      0.79  0.040936  2024-11-23T00:27:58-08:00  2024-11-23T00:40:23-08:00   \n",
       "1      0.81  0.039428  2024-11-23T10:44:13-08:00  2024-11-23T12:07:27-08:00   \n",
       "2      0.67  0.047258  2024-11-23T10:58:18-08:00  2024-11-23T11:36:30-08:00   \n",
       "3      0.82  0.038612  2024-11-23T11:01:41-08:00  2024-11-23T11:03:15-08:00   \n",
       "4      0.80  0.040202  2024-11-23T11:12:29-08:00  2024-11-23T11:13:45-08:00   \n",
       "\n",
       "   run_input_tokens  run_output_tokens  run_total_tokens  upper_bound  \\\n",
       "0             75395              19493             94888     0.870235   \n",
       "1            113609              40982            154591     0.887278   \n",
       "2            116382              39693            156075     0.762626   \n",
       "3             91260              33541            124801     0.895680   \n",
       "4             87505              30140            117645     0.878795   \n",
       "\n",
       "   lower_bound  \n",
       "0     0.709765  \n",
       "1     0.732722  \n",
       "2     0.577374  \n",
       "3     0.744320  \n",
       "4     0.721205  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_run_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diff_mean_accuracy': np.float64(-0.020000000000000018),\n",
       " 'diff_stderr': np.float64(0.0568357548582143),\n",
       " 'upper_bound': np.float64(0.09139807952210001),\n",
       " 'lower_bound': np.float64(-0.13139807952210003),\n",
       " 'z_score': np.float64(-0.35189116516342844),\n",
       " 'is_significant_at_90_confidence': np.False_,\n",
       " 'is_significant_at_95_confidence': np.False_,\n",
       " 'is_significant_at_99_confidence': np.False_,\n",
       " 'is_significant_at_99_9_confidence': np.False_}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Unpaired_analysis\"\"\"\n",
    "\n",
    "def compare_models(df, model1, model2):\n",
    "    model1_mean_accuracy = df[df['model'] == model1]['accuracy'].iloc[0]\n",
    "    model2_mean_accuracy = df[df['model'] == model2]['accuracy'].iloc[0]\n",
    "\n",
    "    model1_stderr = df[df['model'] == model1]['stderr'].iloc[0]\n",
    "    model2_stderr = df[df['model'] == model2]['stderr'].iloc[0]\n",
    "\n",
    "    diff_mean_accuracy = model1_mean_accuracy - model2_mean_accuracy\n",
    "    diff_stderr = np.sqrt(model1_stderr**2 + model2_stderr**2)\n",
    "\n",
    "    upper_bound = diff_mean_accuracy + 1.96 * diff_stderr\n",
    "    lower_bound = diff_mean_accuracy - 1.96 * diff_stderr\n",
    "\n",
    "    z_score = diff_mean_accuracy / diff_stderr\n",
    "\n",
    "    is_significant_at_90_confidence = z_score > 1.645 or z_score < -1.645\n",
    "    is_significant_at_95_confidence = z_score > 1.96 or z_score < -1.96\n",
    "    is_significant_at_99_confidence = z_score > 2.58 or z_score < -2.58\n",
    "    is_significant_at_99_9_confidence = z_score > 3.29 or z_score < -3.29\n",
    "\n",
    "\n",
    "    return {'diff_mean_accuracy': diff_mean_accuracy,\n",
    "            'diff_stderr': diff_stderr,\n",
    "            'upper_bound': upper_bound, \n",
    "            'lower_bound': lower_bound, \n",
    "            'z_score': z_score, \n",
    "            'is_significant_at_90_confidence': is_significant_at_90_confidence, \n",
    "            'is_significant_at_95_confidence': is_significant_at_95_confidence, \n",
    "            'is_significant_at_99_confidence': is_significant_at_99_confidence, \n",
    "            'is_significant_at_99_9_confidence': is_significant_at_99_9_confidence}\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# diff, upper, lower, z = compare_models(all_run_data_df, 'openai/gpt-4', 'anthropic/claude-3-5-sonnet-latest')\n",
    "\n",
    "compare_models(all_run_data_df, 'openai/gpt-4', 'anthropic/claude-3-5-sonnet-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diff_mean_accuracy': np.float64(0.12),\n",
       " 'upper_bound': np.float64(0.24254453735831571),\n",
       " 'lower_bound': np.float64(-0.002544537358315724),\n",
       " 'z_score': np.float64(1.919302198777607),\n",
       " 'is_significant_at_90_confidence': np.True_,\n",
       " 'is_significant_at_95_confidence': np.False_,\n",
       " 'is_significant_at_99_confidence': np.False_,\n",
       " 'is_significant_at_99_9_confidence': np.False_}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(all_run_data_df, 'openai/gpt-4', 'google/gemini-1.5-flash-001')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diff_mean_accuracy': np.float64(0.14),\n",
       " 'diff_stderr': np.float64(0.05321957564959752),\n",
       " 'upper_bound': np.float64(0.24431036827321115),\n",
       " 'lower_bound': np.float64(0.03568963172678888),\n",
       " 'z_score': np.float64(2.6306109789708327),\n",
       " 'is_significant_at_90_confidence': np.True_,\n",
       " 'is_significant_at_95_confidence': np.True_,\n",
       " 'is_significant_at_99_confidence': np.True_,\n",
       " 'is_significant_at_99_9_confidence': np.False_}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Paired_analysis\"\"\"\n",
    "def compare_models_paired(df,df_samples, model1, model2, n_samples=100):\n",
    "    model1_mean_accuracy = df[df['model'] == model1]['accuracy'].iloc[0]\n",
    "    model2_mean_accuracy = df[df['model'] == model2]['accuracy'].iloc[0]\n",
    "\n",
    "\n",
    "    diff_mean_accuracy = model1_mean_accuracy - model2_mean_accuracy\n",
    "\n",
    "    models = [model1, model2]\n",
    "\n",
    "    run_ids = df[df['model'].isin(models)]['run_id'].unique()\n",
    "\n",
    "    run1_df = df_samples[df_samples['run_id'] == run_ids[0]][['run_id', 'sample_id', 'score_binary']]\n",
    "    run2_df = df_samples[df_samples['run_id'] == run_ids[1]][['run_id', 'sample_id', 'score_binary']]\n",
    "\n",
    "    merged_df = run1_df.merge(run2_df, on='sample_id', suffixes=('_run1', '_run2'))\n",
    "\n",
    "    merged_df['score_diff'] = merged_df['score_binary_run1'] - merged_df['score_binary_run2']\n",
    "\n",
    "    merged_df['diff_mean_accuracy'] = diff_mean_accuracy\n",
    "\n",
    "    merged_df['score_diff_agg_sqaured'] = (merged_df['score_diff'] - merged_df['diff_mean_accuracy'])**2\n",
    "\n",
    "    sum_squared_diffs = merged_df['score_diff_agg_sqaured'].sum()\n",
    "\n",
    "    multiplier = 1/(n_samples - 1)\n",
    "\n",
    "    paired_se = ((sum_squared_diffs * multiplier) / n_samples)**0.5\n",
    "\n",
    "    upper_bound = diff_mean_accuracy + 1.96 * paired_se\n",
    "    lower_bound = diff_mean_accuracy - 1.96 * paired_se\n",
    "\n",
    "    z_score = diff_mean_accuracy / paired_se\n",
    "\n",
    "    is_significant_at_90_confidence = z_score > 1.645 or z_score < -1.645\n",
    "    is_significant_at_95_confidence = z_score > 1.96 or z_score < -1.96\n",
    "    is_significant_at_99_confidence = z_score > 2.58 or z_score < -2.58\n",
    "    is_significant_at_99_9_confidence = z_score > 3.29 or z_score < -3.29\n",
    "\n",
    "    return {'diff_mean_accuracy': diff_mean_accuracy,\n",
    "            'diff_stderr': paired_se,\n",
    "            'upper_bound': upper_bound, \n",
    "            'lower_bound': lower_bound, \n",
    "            'z_score': z_score, \n",
    "            'is_significant_at_90_confidence': is_significant_at_90_confidence, \n",
    "            'is_significant_at_95_confidence': is_significant_at_95_confidence, \n",
    "            'is_significant_at_99_confidence': is_significant_at_99_confidence, \n",
    "            'is_significant_at_99_9_confidence': is_significant_at_99_9_confidence}\n",
    "\n",
    "    \n",
    "\n",
    "compare_models_paired(all_run_data_df, all_samples_data_df, 'anthropic/claude-3-5-sonnet-latest', 'google/gemini-1.5-flash-001')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
